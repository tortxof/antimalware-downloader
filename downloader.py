#! /usr/bin/env python3

import os
import re
import subprocess

import requests
from bs4 import BeautifulSoup

dl_dir = 'downloads'

def get_refresh_url(url):
    r = requests.get(url)
    soup = BeautifulSoup(r.text, 'html5')
    if 'bleepingcomputer.com' in url:
        meta_tags = soup.find_all('meta', attrs={'http-equiv': 'refresh'}, content=re.compile('^3'))
        url = meta_tags[0]['content'].split(';')[1].strip().split('url=')[1]
    elif 'geekstogo.com' in url:
        url = soup.find_all(class_='download_button')[0]['href']
    return url

with open('urls.txt') as f:
    urls = f.readlines()

if not os.path.isdir(dl_dir):
    os.mkdir(dl_dir)
os.chdir(dl_dir)

dl_command = ['curl', '-O', '-J']
for i in urls:
    url = get_refresh_url(i)
    r = requests.head(url)
    if r.status_code in [301, 302]:
        url = r.headers['location']
    subprocess.call(dl_command + [url])
